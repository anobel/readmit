---
title: "Comorbidity Indices for Predicting Readmissions"
subtitle: "Machine Learning Approaches"
author: "Anobel Y Odisho, Ruth Etzioni, John L Gore"
date: "`r Sys.Date()`"
output: 
  tufterhandout::html_tufte_handout:
        theme: cosmo
        css: floating.css
        toc: yes
params:
    cohort: ""
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  cache = F,
  dev = 'quartz_pdf')
```

```{r packages, cache=F}
# Data Cleaning Packages
library(parallel)   # for parallel processing mclapply
library(dplyr)      # Data Management
library(tidyr)      # Data Cleaning
library(stringr)    # String manipulation
library(broom)      # Tidy regression results

# Graphics Packages
library(ggplot2)    # Graphics
library(ggthemes)   # Themes for ggplot
library(plotROC)
library(DT)         # HTML Widget for Data Tables
library(stargazer)  # HTML Tables for regression results

# Specialty/Stats Packages
library(ROCR)       # Performance measures, ROC curves, AUC
library(icd)        # ICD package
# library(lme4)     # Mixed Effects Models
# library(coin)     # Permutation Testing
```

```{r constants}
# Define colors for charts
c <- list()
c$dblue <- "#506380"
c$teal <- "#18A3AC"
c$blue <- "#178CCB"
c$orange <- "#F48024"

# HCC names
hccnames <- read.csv("data/raw/hcc/hcc_labels.csv", stringsAsFactors = F)
```

```{r functions}
rocResult <- function (x, add=F) {
  # predict test data result
  pr <- predict(x, newdata=test, allow.new.levels=T)
  pr <- prediction(pr, test$isreadmit30dc)
  auc <- performance(pr, measure="auc") 
  auc <- round(auc@y.values[[1]],4)
  # Generate ROC Curve
  roc <- performance(pr, measure="tpr", x.measure="fpr")
  plot(roc, colorize=T, downsampling=0.5, add=add)
  abline(0,1, col="grey")
  cat("AUC:", auc)
}

# Prepare object for ROC plotting from multiple regressions
# Use this when using a single model from a single do() command
# but that is first grouped by cohorts
# the resulting object is in long format
rocLong <- function (modelDF, groupvar) {
  # modelDF takes output from regression model generated by do()
  # groupvar refers to the grouping variable used
  # create vectors for number of groups and to identify groups
  numgroups <- nrow(modelDF)
  group <- unique(modelDF[[groupvar]])
  # predicted results using test data
  pr <- lapply(1:numgroups, function(x) {
          predict(modelDF[[x,2]],
            newdata=test[test[[groupvar]]==group[x],],
            allow.new.levels=T)
          })
  # create the ROCR prediction object. use for calculating TPR/FPR, AUC
  pr <- lapply(1:numgroups, function(x) {
          prediction(pr[[x]],
                    test$isreadmit30dc[test[[groupvar]]==group[x]])
          })
  # Calculate AUCs
  auc <- lapply(1:numgroups, function(x) {
    performance(pr[[x]], measure="auc")@y.values[[1]]
  })
  # create s4 objeect with TPR and FPR
  pr <- lapply(1:numgroups, function(x) {
          performance(pr[[x]], measure="tpr", x.measure="fpr")
          })
  # flatten prediction object into a dataframe with grouping variables and AUC
  results <- list()
  for (i in 1:numgroups) {
    results[[i]] <- data.frame(
           group = group[i],
           fpr = unlist(pr[[i]]@x.values),
           tpr = unlist(pr[[i]]@y.values),
           cutoff = unlist(pr[[i]]@alpha.values),
           auc = auc[[i]])
  }
  results <- do.call(rbind, results)
  return(results)
}

# Prepare object for ROC plotting from multiple regressions
# Use this when generating multiple models for a single cohort
# from multiple do() commands
# the resulting object is in wide format

rocWide <- function (modelDF) {
  # modelDF takes output from regression model generated by do()
  # groupvar refers to the grouping variable used
  # create vectors for number of groups and to identify groups
  numgroups <- length(modelDF)-1
  group = modelDF[[1,1]]
  # predicted results using test data
  pr <- lapply(2:(numgroups+1), function(x) {
          predict(modelDF[[1, x]],
            newdata=test[test$cohort == group, ],
            allow.new.levels = T)
          })
  # create the ROCR prediction object. use for calculating TPR/FPR, AUC
  pr <- lapply(1:numgroups, function(x) {
          prediction(pr[[x]], test$isreadmit30dc[test$cohort==group])
          })
  # Calculate AUCs
  auc <- lapply(1:numgroups, function(x) {
    performance(pr[[x]], measure="auc")@y.values[[1]]
  })
  # create s4 objeect with TPR and FPR
  pr <- lapply(1:numgroups, function(x) {
          performance(pr[[x]], measure="tpr", x.measure="fpr")
          })
  # flatten prediction object into a dataframe with grouping variables and AUC
  results <- list()
  for (i in 1:numgroups) {
    results[[i]] <- data.frame(
           group = names(modelDF)[i+1],
           fpr = unlist(pr[[i]]@x.values),
           tpr = unlist(pr[[i]]@y.values),
           cutoff = unlist(pr[[i]]@alpha.values),
           auc = auc[[i]])
  }
  results <- do.call(rbind, results)
  return(results)
}

# Calculate AUCs from a single regression result
aucResult <- function(x) {
  # predict test data result
  pr <- predict(x, newdata=test, allow.new.levels=T)
  pr <- prediction(pr, test$isreadmit30dc)
  auc <- performance(pr, measure="auc") 
  auc <- round(auc@y.values[[1]],4)
  return(auc)
}
```

```{r importdata}
# Import data
pt <- readRDS("data/patient/tidy/pt_rml.rds")

# split data into training and validation cohorts
# Set random seed to reproduce results
set.seed(7)

# Create an index variable which will allow splitting of training/test data without overlap
pt$index <- seq(1:nrow(pt))

# Group by OSHPD_ID, then take a 75% sample for training set
train <- pt %>%
  group_by(cohort) %>%
  sample_frac(size=0.75, replace=F)

# Anything that didnt make it into training set is put into a test set
test <- pt[!(pt$index %in% train$index),]

# Remove index variables
pt <- pt %>% select(-index)
train <- train %>% select(-index)
test <- test %>% select(-index)

# Calculate counts
counts <- pt %>%
  group_by(cohort) %>%
  summarise(n = n())

########## Regression Formulas
# save formulas for regression models
elixfm <- paste0(grep("elix_", names(pt), value = T), collapse="+")
elixfm <- as.formula(paste("isreadmit30dc", elixfm, sep="~"))

cdfm <- paste0(grep("cd_", names(pt), value = T), collapse="+")
cdfm <- as.formula(paste("isreadmit30dc", cdfm, sep="~"))

hccfm <- paste0(grep("hcc_", names(pt), value = T), collapse="+")
hccfm <- as.formula(paste("isreadmit30dc", hccfm, sep="~"))
```

# Log Models
## Elixhauser
### Frequency Table
```{r Elix.frequency}
# Calculate frequency table per cohort and join with counts per cohort
freqelix <- pt %>% 
  group_by(cohort) %>%
  dplyr::select(starts_with("elix_")) %>%
  summarise_each(funs(sum)) %>%
  left_join(counts)

# calculate percentages
freqelix <- round(100*freqelix[,grep("elix_", names(freqelix))]/freqelix$n,2)
# bring back cohort labels
freqelix <- cbind(counts[,1], freqelix)

# convert from wide to long and relabel columns, category names
freqelix <- gather(freqelix, cohort, frequency)
names(freqelix) <- c("cohort", "elix", "frequency")
freqelix$elix <- str_replace(freqelix$elix, "elix_", "")

# generate plot: freqnecy by cohort
ggplot(freqelix, aes(x = elix, y = frequency, fill=cohort)) + 
  geom_bar(stat="identity") + 
  facet_grid(cohort ~ .) + 
  scale_fill_brewer(palette="Set1") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme(legend.position="none") + 
  labs(title = "Frequency of Each Elixhauser Category by Cohort", x=element_blank(), y="Frequency")
```

### Individual Predictors
```{r logmodelselix}
glmelix <- pt %>% 
  group_by(cohort) %>%
  do(
    fit = glm(elixfm, data=., family="binomial")
    ) %>% 
  rowwise()

# create a dataframe of tidy results
glmelixres <- glmelix %>% 
  tidy(fit, exponentiate = T)

# Calculate 95% confidence intervals
ci <- mclapply(1:nrow(glmelix), mc.cores = 8, function(x) exp(confint(glmelix[[x,2]])))

# create a vector of cohort names in the model
# use this to organize confidence interval caluclations
cohorts <- glmelix[,1]
cohorts <- unlist(lapply(cohorts, as.character))

# add cohort names to CI calculations
ci <- Map(cbind, ci, cohort = cohorts)
# Combine into one DF and rename columns
ci <- do.call(rbind, ci)
ci <- data.frame(cbind(term = rownames(ci), ci), row.names = NULL, stringsAsFactors = F)
names(ci) <- c("term", "ci.low", "ci.high", "cohort")
# Convert CIs to numeric 
ci$ci.low <- as.numeric(ci$ci.low)
ci$ci.high <- as.numeric(ci$ci.high)

# combine CI calculations with GLM results
glmelixres <- merge(glmelixres, ci)

# Drop intercept terms from charts, clean up term names
glmelixres <- glmelixres %>%
  filter(term!="(Intercept)") %>%
  mutate(term = str_replace_all(term, "elix_|TRUE",""))

# Flag invalid CIs (NAs)
# If any term has invalid CI or estimates, set it all to NA for plotting
invalid <- is.na(rowSums(glmelixres[names(glmelixres) %in% c("estimate", "ci.low", "ci.high")]))
glmelixres$estimate[invalid] <- NA
glmelixres$ci.low[invalid] <- NA
glmelixres$ci.high[invalid] <- NA

# Loop to generate 4 separate plots, one for each cohort
# This shows Odds ratio of each term with 95% CI
for (i in seq_along(unique(glmelix$cohort))){
  plotcohort <- unique(glmelix$cohort)[i]
  plot <- glmelixres %>%
    filter(cohort==plotcohort) %>%
      ggplot(data=., aes(estimate, term, color=term)) +
      geom_point() +
      geom_errorbarh(aes(xmin = ci.low, xmax = ci.high)) +
      geom_vline(xintercept=1) + 
      labs(title=paste(plotcohort, "Cohort Elixhauser Log Regression"), x="Odds Ratio with 95% Confidence Interval", y="") +
    coord_cartesian(xlim=c(0, 5)) + 
    theme_light() + 
    theme(legend.position = "none")
  print(plot)
}
```

### ROC Curves
```{r rocElix, eval = F}
glmrocElix <- train %>%
  group_by(cohort) %>%
  do(
    fit = glm(elixfm, data=., family="binomial")
    )

# Create dataframe for ROC plot
glmrocElix <- rocLong(glmrocElix, "cohort")

# ROC plot
ggplot(glmrocElix, aes(x = fpr, y = tpr, label = cutoff, color = group)) +
  geom_roc(stat = "identity", n.cuts = 0) +
  style_roc() +
  scale_color_brewer(palette = "Set1", name="Cohort",
                    labels = paste(group, " AUC: ", 
                                   round(as.numeric(auc), 3), sep = "")) +
  labs(title = paste("Elixhauser Log Regression by Cohort"))
```

## Charlson-Deyo
```{r logmodelscd}
# Fit the basic log model across all cohorts
glmcd <- pt %>% 
  group_by(cohort) %>%
  do(
    fit = glm(cdfm, data=., family="binomial")
    ) %>% 
  rowwise()

# create a dataframe of tidy results
glmcdres <- glmcd %>% 
  tidy(fit, exponentiate = T)

# Calculate 95% confidence intervals
ci <- mclapply(1:nrow(glmcd), mc.cores = 8, function(x) exp(confint(glmcd[[x,2]])))

# create a vector of cohort names in the model
# use this to organize confidence interval caluclations
cohorts <- glmcd[,1]
cohorts <- unlist(lapply(cohorts, as.character))

# add cohort names to CI calculations
ci <- Map(cbind, ci, cohort = cohorts)
# Combine into one DF and rename columns
ci <- do.call(rbind, ci)
ci <- data.frame(cbind(term = rownames(ci), ci), row.names = NULL, stringsAsFactors = F)
names(ci) <- c("term", "ci.low", "ci.high", "cohort")
# Convert CIs to numeric 
ci$ci.low <- as.numeric(ci$ci.low)
ci$ci.high <- as.numeric(ci$ci.high)

# combine CI calculations with GLM results
glmcdres <- merge(glmcdres, ci)

# Drop intercept terms from charts, clean up term names
glmcdres <- glmcdres %>%
  filter(term!="(Intercept)") %>%
  mutate(term = str_replace_all(term, "cd_|TRUE",""))

# Flag invalid CIs (NAs)
# If any term has invalid CI or estimates, set it all to NA for plotting
invalid <- is.na(rowSums(glmcdres[names(glmcdres) %in% c("estimate", "ci.low", "ci.high")]))
glmcdres$estimate[invalid] <- NA
glmcdres$ci.low[invalid] <- NA
glmcdres$ci.high[invalid] <- NA

# Loop to generate 4 separate plots, one for each cohort
# This shows Odds ratio of each term with 95% CI
for (i in seq_along(unique(glmcd$cohort))){
  plotcohort <- unique(glmcd$cohort)[i]
  plot <- glmcdres %>%
    filter(cohort==plotcohort) %>%
      ggplot(data=., aes(estimate, term, color=term)) +
      geom_point() +
      geom_errorbarh(aes(xmin = ci.low, xmax = ci.high)) +
      geom_vline(xintercept=1) + 
      labs(title=paste(plotcohort, "Cohort Charlson-Deyo Log Regression"), x="Odds Ratio with 95% Confidence Interval", y="") +
    coord_cartesian(xlim=c(0, 5)) + 
    theme_light() + 
    theme(legend.position = "none")
  print(plot)
}
```

### Frequency Table
```{r CD.frequency}
# Calculate frequency table per cohort and join with counts per cohort
freqcd <- pt %>% 
  group_by(cohort) %>%
  dplyr::select(starts_with("cd_")) %>%
  summarise_each(funs(sum)) %>%
  left_join(counts)

# calculate percentages
freqcd <- round(100*freqcd[,grep("cd_", names(freqcd))]/freqcd$n,2)
# bring back cohort labels
freqcd <- cbind(counts[,1], freqcd)

# convert from wide to long and relabel columns, category names
freqcd <- gather(freqcd, cohort, frequency)
names(freqcd) <- c("cohort", "cd", "frequency")
freqcd$cd <- str_replace(freqcd$cd, "cd_", "")

# generate plot: freqnecy by cohort
ggplot(freqcd, aes(x = cd, y = frequency, fill=cohort)) + 
  geom_bar(stat="identity") + 
  facet_grid(cohort ~ .) + 
  scale_fill_brewer(palette="Set1") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme(legend.position="none") + 
  labs(title = "Frequency of Each Charlson-Deyo Category by Cohort", x=element_blank(), y="Frequency")
```

### ROC Curves
```{r rocCD}
glmrocCD <- train %>%
  group_by(cohort) %>%
  do(
    fit = glm(cdfm, data=., family="binomial")
    )

# Create dataframe for ROC plot
glmrocCD <- rocLong(glmrocCD, "cohort")

# ROC plot
ggplot(glmrocCD, aes(x = fpr, y = tpr, label = cutoff, color = group)) +
  geom_roc(stat = "identity", n.cuts = 0) +
  style_roc() +
  scale_color_brewer(palette = "Set1", name="Cohort",
                    labels = paste(group, " AUC: ", 
                                   round(as.numeric(auc), 3), sep = "")) +
  labs(title = paste("Charlson-Deyo Log Regression by Cohort"))
```

## HCC
```{r logmodelshcc}
# Fit the basic log model across all cohorts
glmhcc <- pt %>% 
  group_by(cohort) %>%
  do(
    fit = glm(hccfm, data=., family="binomial")
    ) %>% 
  rowwise()

# create a dataframe of tidy results
glmhccres <- glmhcc %>% 
  tidy(fit, exponentiate = T)

# Calculate 95% confidence intervals
ci <- mclapply(1:nrow(glmhcc), mc.cores=8, function(x) exp(confint(glmhcc[[x,2]])))

# create a vector of cohort names in the model
# use this to organize confidence interval caluclations
cohorts <- glmhcc[,1]
cohorts <- unlist(lapply(cohorts, as.character))

# add cohort names to CI calculations
ci <- Map(cbind, ci, cohort = cohorts)
# Combine into one DF and rename columns
ci <- do.call(rbind, ci)
ci <- data.frame(cbind(term = rownames(ci), ci), row.names = NULL, stringsAsFactors = F)
names(ci) <- c("term", "ci.low", "ci.high", "cohort")
# Convert CIs to numeric 
ci$ci.low <- as.numeric(ci$ci.low)
ci$ci.high <- as.numeric(ci$ci.high)

# combine CI calculations with GLM results
glmhccres <- merge(glmhccres, ci)

# Drop intercept terms from charts, clean up term names
glmhccres <- glmhccres %>%
  filter(term!="(Intercept)") %>%
  mutate(term = str_replace_all(term, "hcc_|TRUE",""))

# Flag invalid CIs (NAs)
# If any term has invalid CI or estimates, set it all to NA for plotting
invalid <- is.na(rowSums(glmhccres[names(glmhccres) %in% c("estimate", "ci.low", "ci.high")]))
glmhccres$estimate[invalid] <- NA
glmhccres$ci.low[invalid] <- NA
glmhccres$ci.high[invalid] <- NA

# some HCCs not represented in different cohorts, so make blank DF
# and bind just the missing ones back to main results DF 
blanks <- data.frame(cohort = rep(cohorts, each = nrow(hccnames)),
                     term = hccnames$hcc_short,
                     estimate = NA, std.error = NA, statistic = NA,
                     p.value = NA, ci.low = NA, ci.high = NA)

blanks <- glmhccres %>%
  group_by(cohort) %>%
   do (blanks[blanks$cohort %in% .$cohort & !(hccnames$hcc_short %in% .$term),])

glmhccres <- rbind(glmhccres, blanks)

# Loop to generate 4 separate plots, one for each cohort
# This shows Odds ratio of each term with 95% CI
for (i in seq_along(unique(glmhcc$cohort))){
  plotcohort <- unique(glmhcc$cohort)[i]
  plot <- glmhccres %>%
    filter(cohort==plotcohort) %>%
      ggplot(data=., aes(estimate, term, color=term)) +
      geom_point() +
      geom_errorbarh(aes(xmin = ci.low, xmax = ci.high)) +
      geom_vline(xintercept=1) + 
      labs(title=paste(plotcohort, "Cohort HCC Log Regression"), x="Odds Ratio with 95% Confidence Interval", y="") +
    coord_cartesian(xlim=c(0, 5)) + 
    theme_light() + 
    theme(legend.position = "none")
  print(plot)
}
```

### Frequency Table
```{r HCC.frequency}
# Calculate frequency table per cohort and join with counts per cohort
freqhcc <- pt %>% 
  group_by(cohort) %>%
  dplyr::select(starts_with("hcc_")) %>%
  summarise_each(funs(sum)) %>%
  left_join(counts)

# calculate percentages
freqhcc <- round(100*freqhcc[,grep("hcc_", names(freqhcc))]/freqhcc$n,2)
# bring back cohort labels
freqhcc <- cbind(counts[,1], freqhcc)

# convert from wide to long and relabel columns, category names
freqhcc <- gather(freqhcc, cohort, frequency)
names(freqhcc) <- c("cohort", "hcc", "frequency")
freqhcc$hcc <- str_replace(freqhcc$hcc, "hcc_", "")

# generate plot: freqnecy by cohort
ggplot(freqhcc, aes(x = hcc, y = frequency, fill=cohort)) + 
  geom_bar(stat="identity") + 
  facet_grid(cohort ~ .) + 
  scale_fill_brewer(palette="Set1") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  theme(legend.position="none") + 
  labs(title = "Frequency of Each HCC by Cohort", x=element_blank(), y="Frequency")
```

### ROC Curves
When using the 75% training data, there are insufficient observations to fit the model (rank-deficient). At this point, will keep the code here for when additional data are available, but it is currently not evaluated. 
```{r rocHCC, eval = F}
glmrocHCC <- train %>%
  group_by(cohort) %>%
  do(
    fit = glm(hccfm, data=., family="binomial")
    )

# Create dataframe for ROC plot
glmrocHCC <- rocLong(glmrocHCC, "cohort")

# ROC plot
ggplot(glmrocHCC, aes(x = fpr, y = tpr, label = cutoff, color = group)) +
  geom_roc(stat = "identity", n.cuts = 0) +
  style_roc() +
  scale_color_brewer(palette = "Set1", name="Cohort",
                    labels = paste(group, " AUC: ", 
                                   round(as.numeric(auc), 3), sep = "")) +
  labs(title = paste("HCC Log Regression by Cohort"))
```

## Comparings Indices
### Cystectomy
As above, insufficient data in training data, so cystectomy models cannot be fit. 

### Random Cohort
```{r rocglmRandom, eval = T}
glmrocProc <- train %>%
  filter(cohort=="Random") %>%
  do(
    glmelix = glm(elixfm, data=., family="binomial"),
    glmcd = glm(cdfm, data=., family="binomial"),
    glmhcc = glm(hccfm, data=., family="binomial")
    )

# Create dataframe for ROC plot
glmrocProc <- rocWide(glmrocProc)

# ROC plot
ggplot(glmrocProc, aes(x = fpr, y = tpr, label = cutoff, color = group)) +
  geom_roc(stat = "identity", n.cuts = 0) +
  style_roc() +
  scale_color_brewer(palette = "Set1", name = "Model",
                    labels = paste(unique(results$group), " AUC: ", 
                                   round(as.numeric(auc), 3), sep = "")) +
  labs(title = paste("Random Cohort Log Regression"))
```

# HCC Model Selection
```{r hccModelSelection}
hccmodels <- train %>%
  group_by(cohort) %>%
  do(
    glmhcc = glm(hccfm, data=., family="binomial")
    )
t <- train %>% filter(cohort=="RadNx")

100*prop.table(table(t$hcc_HIV))


train %>%
  select(cohort=="Cystectomy") %>%
  step()



```
